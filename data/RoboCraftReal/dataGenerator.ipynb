{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86efe403",
   "metadata": {},
   "source": [
    "## Read raw data and generate timestamped graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd71659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "data_dirname = \"/coc/flash5/mpatel377/repos/SLaTe-PRO/data/RoboCraft/rawAnnotated\"\n",
    "\n",
    "list_of_datafiles = json.load(open(os.path.join(data_dirname, \"../phase1_train_data.json\")))\n",
    "\n",
    "VERBOSE = False\n",
    "NO_SUPPLYSHELF = True\n",
    "\n",
    "shutil.rmtree(\"processed_seqLM_coarse\", ignore_errors=True)\n",
    "shutil.rmtree(\"human_readable\", ignore_errors=True)\n",
    "os.makedirs(\"human_readable\", exist_ok=True)\n",
    "os.makedirs(\"processed_seqLM_coarse/all\", exist_ok=True)\n",
    "os.makedirs(\"processed_seqLM_coarse/figures\", exist_ok=True)\n",
    "\n",
    "def flog(message):\n",
    "    print(message)\n",
    "    with open(\"processed_seqLM_coarse/log.txt\", \"a\") as f:\n",
    "        f.write(message + \"\\n\")\n",
    "\n",
    "\n",
    "print(f\"Start time: {TIME_START_SECONDS} seconds ({TIME_START_SECONDS-TIME_START_SECONDS} duration = {time_seconds_to_hhmmss(TIME_START_SECONDS)} HHMMSS\")\n",
    "print(f\"End time: {TIME_END_SECONDS} seconds ({TIME_END_SECONDS-TIME_START_SECONDS} duration) = {time_seconds_to_hhmmss(TIME_END_SECONDS)} HHMMSS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227762cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for filename in os.listdir(data_dirname):\n",
    "    if filename.endswith(\".json\"):\n",
    "        metadata = filename.split(\"_export\")[0]\n",
    "        camera = metadata.split(\"_\")[1].split(\"-\")[-1]\n",
    "        date = \"-\".join(metadata.split(\"_\")[0].split('-')[:3])\n",
    "        start_time = metadata.split(\"_\")[0].split('-')[-1]\n",
    "        table_name = [entry[\"table_name\"] for entry in list_of_datafiles if entry[\"date\"] == date and entry[\"camera_id\"] == camera]\n",
    "        if len(table_name) == 0:\n",
    "            print(f\"No table name found for {date} {camera}\")\n",
    "            continue\n",
    "        table_name = lowercase_table_name(table_name[0])\n",
    "        print(\"Date: \", date)\n",
    "        print(\"Camera: \", camera)\n",
    "        print(\"Filename: \", filename)\n",
    "        print(\"Table Name: \", table_name)\n",
    "        if date not in data:\n",
    "            data[date] = {}\n",
    "        data[date][table_name] = process_frames(json.load(open(os.path.join(data_dirname, filename), \"r\"))[\"frames\"], start_time)\n",
    "        print(\"Number of frames: \", len(json.load(open(os.path.join(data_dirname, filename), \"r\"))[\"frames\"]))\n",
    "        print()\n",
    "        \n",
    "for date in data:\n",
    "    for table_name in ['tableA', 'tableB', 'tableC', 'tableD', 'tableE']:\n",
    "        if table_name not in data[date]:\n",
    "            data[date][table_name] = {}\n",
    "\n",
    "## Sort data by date\n",
    "data = {date: data[date] for date in sorted(data.keys())}\n",
    "\n",
    "## Sort data by table name\n",
    "for date in data:\n",
    "    data[date] = {table_name: data[date][table_name] for table_name in sorted(data[date].keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimestr = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "data_filename_processed = f\"/coc/flash5/mpatel377/repos/SLaTe-PRO/data/RoboCraft/processedData_GT.json\"\n",
    "\n",
    "json.dump(data, open(data_filename_processed,'w'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc243acf",
   "metadata": {},
   "source": [
    "## Read in robot timestamps and filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ba05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_timestamps = {data:{table:{} for table in ['tableA', 'tableB', 'tableC', 'tableD', 'tableE']} for data in data}\n",
    "robot_timestamps_raw = json.load(open(\"/coc/flash5/mpatel377/repos/SLaTe-PRO/data/RoboCraft/robot_timestamps.json\", \"r\"))\n",
    "        \n",
    "for robot_timestamp_i in robot_timestamps_raw:\n",
    "    if robot_timestamp_i[\"day\"] not in robot_timestamps: continue\n",
    "    table_name = robot_timestamp_i[\"table_name\"].replace(\"_\",\"\")\n",
    "    robot_timestamp_i[\"table_start_time\"] = time_hhmmss_to_seconds(robot_timestamp_i[\"table_start_time\"])-TIME_START_SECONDS\n",
    "    robot_timestamp_i[\"marker_start_time\"] = time_hhmmss_to_seconds(robot_timestamp_i[\"marker_start_time\"])-TIME_START_SECONDS\n",
    "    if int(robot_timestamp_i[\"table_start_time\"]) not in robot_timestamps[robot_timestamp_i[\"day\"]][table_name]:\n",
    "        robot_timestamps[robot_timestamp_i[\"day\"]][table_name][int(robot_timestamp_i[\"table_start_time\"])] = []\n",
    "    robot_timestamps[robot_timestamp_i[\"day\"]][table_name][int(robot_timestamp_i[\"table_start_time\"])].append(int(robot_timestamp_i[\"marker_start_time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "\n",
    "for idx, day in enumerate(robot_timestamps):\n",
    "    for table in robot_timestamps[day]:\n",
    "        for timestamp in robot_timestamps[day][table]:\n",
    "            plt.plot((timestamp/60), idx, 'o', color=colors_table[table], markersize=5)\n",
    "            for subtimestamp in robot_timestamps[day][table][timestamp]:\n",
    "                plt.plot((subtimestamp/60), idx-0.1, 'x', color=colors_table[table], markersize=5, alpha=0.5)\n",
    "\n",
    "for table, color in colors_table.items():\n",
    "    plt.plot(0,-0.1, 'o', color=color, label=table)\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Date\")\n",
    "ax.set_xlim(0, ax.get_xlim()[1])\n",
    "plt.title(\"Robot Timestamps\")\n",
    "ax.set_yticks(list(range(len(robot_timestamps))))\n",
    "ax.set_yticklabels(list(robot_timestamps.keys()))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbbb6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_egocentric = {date: {table_name: {timestamp: [] for timestamp in robot_timestamps[date][table_name]} for table_name in robot_timestamps[date]} for date in robot_timestamps}\n",
    "\n",
    "def aggregate_scenegraphs(scenegraphs):\n",
    "    scene_graph_combined = scenegraphs[0]\n",
    "    for scenegraph_this in scenegraphs[1:]:\n",
    "        new_objects = Counter(scenegraph_this) - Counter(scene_graph_combined)\n",
    "        for object, count in new_objects.items():\n",
    "            if count > 0:\n",
    "                scene_graph_combined += [object] * count\n",
    "    return scene_graph_combined\n",
    "\n",
    "for date in data_egocentric:\n",
    "    for table_name in data_egocentric[date]:\n",
    "        for timestamp in data_egocentric[date][table_name]:\n",
    "            subscenegraphs = []\n",
    "            if len(data[date][table_name]) == 0:\n",
    "                VERBOSE and print(f\"No data for {date} {table_name}\")\n",
    "                data_egocentric[date][table_name] = {}\n",
    "                continue\n",
    "            VERBOSE and print(f\"Looking for {robot_timestamps[date][table_name][timestamp]}\")\n",
    "            for subtimestamp in robot_timestamps[date][table_name][timestamp]:\n",
    "                closest_timestamp_in_data = min(data[date][table_name].keys(), key=lambda x: abs(x - subtimestamp))\n",
    "                VERBOSE and print(f\"Found {closest_timestamp_in_data}\", end=\", \")\n",
    "                subscenegraphs.append(data[date][table_name][closest_timestamp_in_data])\n",
    "            VERBOSE and print()\n",
    "            if len(subscenegraphs) == 0:\n",
    "                VERBOSE and print(f\"No observations found for {date} {table_name}\")\n",
    "                data_egocentric[date][table_name] = {}\n",
    "            else:\n",
    "                data_egocentric[date][table_name][timestamp] = aggregate_scenegraphs(subscenegraphs)\n",
    "\n",
    "\n",
    "json.dump(data_egocentric, open(data_filename_processed.replace(\"GT\", \"ego\"), \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb5898a",
   "metadata": {},
   "source": [
    "### !!! Override using all graphs !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_egocentric = data\n",
    "# flog(\"USING OVERHEAD DATA WITHOUT ROBOT FILTERING!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find median difference between timestamps over all tables and dates\n",
    "timestamp_diffs = []\n",
    "for date in data_egocentric:\n",
    "    for table_name in data_egocentric[date]:\n",
    "        timestamps = list(data_egocentric[date][table_name].keys())\n",
    "        timestamps.sort()\n",
    "        timestamp_diffs.extend(np.diff(timestamps))\n",
    "\n",
    "thresh = 60*30\n",
    "print(f\"Median timestamp difference: {np.median([t for t in timestamp_diffs if t<thresh])/60} minutes\")\n",
    "plt.hist(np.array(timestamp_diffs)/60, bins=100)\n",
    "plt.plot([thresh/60, thresh/60], [0, 25], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0f163",
   "metadata": {},
   "source": [
    "## Generate graph sequences in SLaTe-PRO format with constant timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63389da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_masterlist = open(\"../../object_list.txt\", \"r\").read().splitlines()\n",
    "tables = [o for o in objects_masterlist if o.startswith(\"table\")]\n",
    "supplyshelf = [o for o in objects_masterlist if o.startswith(\"supply\")]\n",
    "if NO_SUPPLYSHELF: \n",
    "    supplyshelf = []\n",
    "    objects_masterlist.remove(\"supplyshelf\")\n",
    "\n",
    "surfaces = tables + supplyshelf\n",
    "room = [o for o in objects_masterlist if o.startswith(\"room\")]\n",
    "objects = [o for o in objects_masterlist if o not in tables and o not in supplyshelf and o not in room]\n",
    "\n",
    "print(\"Objects Masterlist:\", ', '.join(objects_masterlist))\n",
    "print(\"Tables:\", ', '.join(tables))\n",
    "print(\"Supply Shelves:\", ', '.join(supplyshelf))\n",
    "print(\"Rooms:\", ', '.join(room))\n",
    "print(\"Objects:\", ', '.join(objects))\n",
    "print(\"Surfaces:\", ', '.join(surfaces))\n",
    "\n",
    "static_graph_edges = torch.zeros(len(objects_masterlist), len(objects_masterlist), dtype=torch.float32)\n",
    "active_edges_mask = torch.zeros_like(static_graph_edges, dtype=torch.float32)\n",
    "for surface in surfaces:\n",
    "    static_graph_edges[objects_masterlist.index(surface), objects_masterlist.index(\"room\")] = 1.0\n",
    "    for object in objects:\n",
    "        active_edges_mask[objects_masterlist.index(object), objects_masterlist.index(surface)] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898f5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10.0\n",
    "print(\"Using dt: \", dt)\n",
    "\n",
    "common_data = {\n",
    "    'dt': dt,\n",
    "    'start_time': 0.0,\n",
    "    'end_time': 60*3,\n",
    "    'node_classes': objects_masterlist,\n",
    "    'node_categories': ['Rooms' if obj in room else 'Furniture' if obj in surfaces else 'placable_objects' for obj in objects_masterlist],\n",
    "    'edge_keys': [\"ON\"],\n",
    "    'static_nodes': [obj for obj in objects_masterlist if obj not in objects],\n",
    "    'static_node_categories': [\"Rooms\", \"Furniture\"],\n",
    "    'dataset_type': \"RoboCraft\",\n",
    "    'n_stations': 5,\n",
    "    'stations': ['tableA', 'tableB', 'tableC', 'tableD', 'tableE'],\n",
    "    'dates': list(data_egocentric.keys()),\n",
    "    'active_edge_ranges': \n",
    "        [[int(np.where(active_edges_mask)[1].min()), int(np.where(active_edges_mask)[1].max())],\n",
    "         [int(np.where(active_edges_mask)[0].min()), int(np.where(active_edges_mask)[0].max())]]\n",
    "}\n",
    "json.dump(common_data, open(\"processed_seqLM_coarse/common_data.json\", \"w\"), indent=4)\n",
    "\n",
    "common_edge_data = {}\n",
    "common_edge_data['home_graph'] = static_graph_edges.clone()\n",
    "for obj in objects:\n",
    "    common_edge_data['home_graph'][objects_masterlist.index(obj), objects_masterlist.index('room')] = 1.0\n",
    "common_edge_data['nonstatic_edges'] = active_edges_mask.clone()\n",
    "common_edge_data['seen_edges'] = torch.zeros_like(active_edges_mask, dtype=torch.float32)\n",
    "torch.save(common_edge_data, \"processed_seqLM_coarse/common_edge_data.pt\")\n",
    "\n",
    "common_embedding_map = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_slatepro_format(sg_egocentric):\n",
    "    ## sg_egocentric is a dictionary of table_name -> list of objects\n",
    "    sg_slatepro = torch.zeros(len(objects_masterlist), len(objects_masterlist), dtype=torch.float32)\n",
    "    persons_per_table = torch.zeros((common_data['n_stations']), dtype=torch.float32)\n",
    "    for table_name, objects in sg_egocentric.items():\n",
    "        for object in objects:\n",
    "            if object == \"person\":\n",
    "                persons_per_table[common_data['stations'].index(table_name)] += 1\n",
    "            else:\n",
    "                sg_slatepro[objects_masterlist.index(object), objects_masterlist.index(table_name)] = 1.0\n",
    "    if not NO_SUPPLYSHELF:\n",
    "        for object in objects:\n",
    "            sg_slatepro[objects_masterlist.index(object), objects_masterlist.index(supplyshelf[0])] = 1.0\n",
    "        \n",
    "    return sg_slatepro, persons_per_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bede829",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_num_movements = []\n",
    "average_prob_of_movement = []\n",
    "for date, data_egocentric_this_date in data_egocentric.items():\n",
    "    VERBOSE and print(f\"\\n\\nProcessing {date}\")\n",
    "    nodes = torch.tensor([i for i in range(len(objects_masterlist))], dtype=torch.float32)\n",
    "    times = torch.arange(common_data['start_time']-common_data['dt'], common_data['end_time'], common_data['dt'], dtype=torch.float32)\n",
    "    scene_graph_list = []\n",
    "    activity_list = []\n",
    "    fig, ax = plt.subplots(1, len(times))\n",
    "    ax = ax.flatten()\n",
    "    number_of_movements = 0\n",
    "    number_of_possible_movements = 0\n",
    "    ax[0].set_yticks(np.arange(0, len(objects_masterlist)), labels=objects_masterlist, fontsize=10)\n",
    "    movements = \"\"\n",
    "    for idx, timestamp_slatepro in enumerate(times):\n",
    "        sg_egocentric = {}\n",
    "        VERBOSE and print(f\"Timestamp: {timestamp_slatepro*60}\")\n",
    "        for table_name in common_data['stations']:\n",
    "            if len(data_egocentric_this_date[table_name]) == 0:\n",
    "                VERBOSE and print(f\"{table_name}: No data\")\n",
    "                sg_egocentric[table_name] = []\n",
    "                continue\n",
    "            most_recent_timestamp = min(data_egocentric_this_date[table_name].keys(), key=lambda x: (abs(x - timestamp_slatepro*60) if (timestamp_slatepro*60 >= x) else float('inf')))\n",
    "            if most_recent_timestamp > timestamp_slatepro*60:\n",
    "                VERBOSE and print(f\"{table_name}: No timestamp found\")\n",
    "                sg_egocentric[table_name] = []\n",
    "            else:\n",
    "                VERBOSE and print(f\"{table_name}: Found {most_recent_timestamp/60}\")\n",
    "                sg_egocentric[table_name] = data_egocentric_this_date[table_name][most_recent_timestamp]\n",
    "        sg, per = convert_to_slatepro_format(sg_egocentric)\n",
    "        if len(scene_graph_list) > 0:\n",
    "            sg_viz = sg.clone()-scene_graph_list[-1]\n",
    "            number_of_movements += sg_viz.sum().abs()\n",
    "            number_of_possible_movements += torch.numel(sg_viz[active_edges_mask.to(bool)])\n",
    "            VERBOSE and print(f\"Number of movements: {number_of_movements}\", end=\"\\r\")\n",
    "            if torch.any(sg_viz > 0):\n",
    "                xx, yy = np.where(sg_viz > 0)\n",
    "                for obj_x, obj_y in zip(xx, yy):\n",
    "                    movements += f\"[{(time_seconds_to_hhmmss(timestamp_slatepro*60, return_human_readable=True))[:-3]}] {objects_masterlist[obj_y]}: Fetch {objects_masterlist[obj_x]}\\n\"\n",
    "            if torch.any(sg_viz < 0):\n",
    "                xx, yy = np.where(sg_viz < 0)\n",
    "                for obj_x, obj_y in zip(xx, yy):\n",
    "                    movements += f\"[{(time_seconds_to_hhmmss(timestamp_slatepro*60, return_human_readable=True))[:-3]}] {objects_masterlist[obj_y]}: Return {objects_masterlist[obj_x]}\\n\"\n",
    "            flog(movements)\n",
    "        else:\n",
    "            sg_viz = sg.clone()\n",
    "        sg_viz[sg_viz > 0] = 1\n",
    "        sg_viz[0,0] = 1\n",
    "        ax[idx].imshow(sg_viz, cmap='viridis', vmin=-1, vmax=1)\n",
    "        # ax[idx].imshow(active_edges_mask, cmap='gray', alpha=0.3)\n",
    "        ax[idx].set_title(f\"{int(timestamp_slatepro)} mins\")\n",
    "        scene_graph_list.append(sg)\n",
    "        activity_list.append(per)\n",
    "        if len(scene_graph_list) == 1:\n",
    "            scene_graph_list.append(sg)\n",
    "            activity_list.append(per)\n",
    "        ax[idx].set_xticks(np.arange(0, len(objects_masterlist)), labels=objects_masterlist, fontsize=10, rotation=90)\n",
    "        ax[idx].set_xlim(np.where(active_edges_mask)[1].min(), np.where(active_edges_mask)[1].max())\n",
    "        ax[idx].set_ylim(np.where(active_edges_mask)[0].min(), np.where(active_edges_mask)[0].max())\n",
    "    average_num_movements.append(number_of_movements)\n",
    "    average_prob_of_movement.append(number_of_movements/number_of_possible_movements)\n",
    "    flog(f\"Number of movements recorded for {date}: {number_of_movements}\")\n",
    "    flog(f\"Probability of object movement: {number_of_movements/number_of_possible_movements} ({number_of_movements}/{number_of_possible_movements})\")\n",
    "\n",
    "    fig.suptitle(date)\n",
    "    fig.set_size_inches(1.5*len(times), 5)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"processed_seqLM_coarse/figures/{date}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    times = torch.cat([times[:1]-common_data['dt'], times])\n",
    "    # times = torch.cat([times[:1]-common_data['dt'], times, times[-1:]+common_data['dt']])\n",
    "    scene_graph_list = [scene_graph_list[0]]+scene_graph_list\n",
    "    activity_list = [activity_list[0]]+activity_list\n",
    "    \n",
    "    torch.save({\n",
    "            'nodes': nodes,\n",
    "            'edges': torch.stack(scene_graph_list, dim=0),\n",
    "            'times': times,\n",
    "            'active_edges': active_edges_mask,\n",
    "            'activity': torch.stack(activity_list, dim=0),\n",
    "        }, f\"processed_seqLM_coarse/all/{date}.pt\")\n",
    "    open(f\"human_readable/{date}.txt\", \"w\").write(movements)\n",
    "    \n",
    "    print(f\"Written to processed_seqLM_coarse/all/{date}.pt\")\n",
    "    \n",
    "flog(f\"Average number of movements: {sum(average_num_movements)/len(average_num_movements)}\")\n",
    "flog(f\"Average probability of object movement: {sum(average_prob_of_movement)/len(average_prob_of_movement)}\")\n",
    "\n",
    "p = sum(average_prob_of_movement)/len(average_prob_of_movement)\n",
    "flog(f\"Random model performance: \\n\\tTP={p*p}, \\n\\tFP/TN={p*(1-p)}, \\n\\tFN={(1-p)*(1-p)}, \\n\\tPrecision={p*p/(p*p+(1-p)*p)}, \\n\\tRecall={p*p/(p*p+(1-p)*p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8844b9",
   "metadata": {},
   "source": [
    "## Temporary patches to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8fa01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copytree(\"processed_seqLM_coarse/all\", \"processed_seqLM_coarse/train\")\n",
    "shutil.copytree(\"processed_seqLM_coarse/all\", \"processed_seqLM_coarse/test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
